{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31905bb8-e505-4133-a27c-1fa209dd320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211e0412-baa9-47f8-8f5b-373f7c78b8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13351609 entries, 0 to 13351608\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   VendorID               int64  \n",
      " 1   tpep_pickup_datetime   object \n",
      " 2   tpep_dropoff_datetime  object \n",
      " 3   passenger_count        int64  \n",
      " 4   trip_distance          float64\n",
      " 5   pickup_longitude       float64\n",
      " 6   pickup_latitude        float64\n",
      " 7   RateCodeID             int64  \n",
      " 8   store_and_fwd_flag     object \n",
      " 9   dropoff_longitude      float64\n",
      " 10  dropoff_latitude       float64\n",
      " 11  payment_type           int64  \n",
      " 12  fare_amount            float64\n",
      " 13  extra                  float64\n",
      " 14  mta_tax                float64\n",
      " 15  tip_amount             float64\n",
      " 16  tolls_amount           float64\n",
      " 17  improvement_surcharge  float64\n",
      " 18  total_amount           float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as p\n",
    "df = p.read_csv(\"yellow_tripdata_2015-03.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a401b31e-c859-44f0-b1ff-291a1f3ec921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13351609 entries, 0 to 13351608\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   VendorID               int64  \n",
      " 1   pickup_datetime        object \n",
      " 2   dropoff_datetime       object \n",
      " 3   passenger_count        int64  \n",
      " 4   trip_distance          float64\n",
      " 5   pickup_longitude       float64\n",
      " 6   pickup_latitude        float64\n",
      " 7   RateCodeID             int64  \n",
      " 8   store_and_fwd_flag     object \n",
      " 9   dropoff_longitude      float64\n",
      " 10  dropoff_latitude       float64\n",
      " 11  payment_type           int64  \n",
      " 12  fare_amount            float64\n",
      " 13  extra                  float64\n",
      " 14  mta_tax                float64\n",
      " 15  tip_amount             float64\n",
      " 16  tolls_amount           float64\n",
      " 17  improvement_surcharge  float64\n",
      " 18  total_amount           float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns = {'tpep_pickup_datetime':'pickup_datetime', 'tpep_dropoff_datetime': 'dropoff_datetime' })\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f947e9ec-bb6a-46c0-98e6-742fa53bdf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: YellowTripData\n",
    "file_name: yellow_tripdata_2015-03\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - vendorid\n",
    "    - pickup_datetime\n",
    "    - dropoff_datetime\n",
    "    - passenger_count\n",
    "    - trip_distance\n",
    "    - pickup_longitude\n",
    "    - pickup_latitude\n",
    "    - ratecodeid\n",
    "    - store_and_fwd_flag\n",
    "    - dropoff_longitude\n",
    "    - dropoff_latitude\n",
    "    - payment_type\n",
    "    - fare_amount\n",
    "    - extra\n",
    "    - mta_tax\n",
    "    - tip_amount\n",
    "    - tolls_amount\n",
    "    - improvement_surcharge\n",
    "    - total_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cd19e3-dc59-4dc1-989b-ecab9a4fcba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'YellowTripData',\n",
       " 'file_name': 'yellow_tripdata_2015-03',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['vendorid',\n",
       "  'pickup_datetime',\n",
       "  'dropoff_datetime',\n",
       "  'passenger_count',\n",
       "  'trip_distance',\n",
       "  'pickup_longitude',\n",
       "  'pickup_latitude',\n",
       "  'ratecodeid',\n",
       "  'store_and_fwd_flag',\n",
       "  'dropoff_longitude',\n",
       "  'dropoff_latitude',\n",
       "  'payment_type',\n",
       "  'fare_amount',\n",
       "  'extra',\n",
       "  'mta_tax',\n",
       "  'tip_amount',\n",
       "  'tolls_amount',\n",
       "  'improvement_surcharge',\n",
       "  'total_amount']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utility\n",
    "config_data = utility.read_config_file(\"file.yaml\")\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cee418a-194e-4675-9a9d-75c1e4a9dd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['VendorID', 'pickup_datetime', 'dropoff_datetime', 'passenger_count',\n",
      "       'trip_distance', 'pickup_longitude', 'pickup_latitude', 'RateCodeID',\n",
      "       'store_and_fwd_flag', 'dropoff_longitude', 'dropoff_latitude',\n",
      "       'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount',\n",
      "       'tolls_amount', 'improvement_surcharge', 'total_amount'],\n",
      "      dtype='object')\n",
      "columns of YAML are: ['vendorid', 'pickup_datetime', 'dropoff_datetime', 'passenger_count', 'trip_distance', 'pickup_longitude', 'pickup_latitude', 'ratecodeid', 'store_and_fwd_flag', 'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns of files are:\" ,df.columns)\n",
    "print(\"columns of YAML are:\" ,config_data['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f72d9b7-a252-41fe-bd04-607b1710698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    }
   ],
   "source": [
    "utility.col_header_val(df,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a23b8d-6ed1-4a79-8583-379ef4e9c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('yellow_tripdata_2015-03.gz', compression = 'gzip', sep = '|', header = False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
